{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deiros_Jeronimo_ejercicio_1_gpu.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzcXc1SGNkHmrR46SEcgGD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdeiros/soa-2020/blob/master/HPC/Deiros_Jeronimo_ejercicio_1_gpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktOqK1RQusis"
      },
      "source": [
        "#1. Introducción\n",
        "\n",
        "Por lo general, las computadoras se utilizan para compilar y analizar los resultados de encuestas y estudios de opinión.\n",
        "\n",
        "El siguiente cuaderno calcula la **moda** de los **N** valores de los elementos de un vector (vector_resultados), lo hace en forma paralela utilizando GPGPU. Cada elemento del vector se inicializa con resultados aleatorios de puntajes (numeros enteros entre 0 y 9).\n",
        "\n",
        "El algoritmo se basa en un ejemplo práctico del libro \"C/C++ Cómo Programar\"[1] \n",
        "\n",
        "Su objetivo es aprender a utilizar Python[2] en la plataforma Colab [3] y CUDA[5,6].  Mostrando el funcionamiento y granularidad (grilla, bloque, warps) de sobre una dimensión (x)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qty_DG4vCSb"
      },
      "source": [
        "#2. Armado de ambiente\n",
        "\n",
        "Instalación de modulo CUDA  de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4_tXQSa5s8g",
        "outputId": "8fdab232-e9ea-4b48-d9ad-93357d492f03"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/61/47d3235a4c13eec5a5f03594ddb268f4858734e02980afbcd806e6242fa5/pycuda-2020.1.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.5MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/30/c9362a282ef89106768cba9d884f4b2e4f5dc6881d0c19b478d2a710b82b/pytools-2020.4.3.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.18.5)\n",
            "Requirement already satisfied: dataclasses>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (0.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2020.1-cp36-cp36m-linux_x86_64.whl size=621008 sha256=6ad3d8c17dbcd2bee2c64dd6a373a0967d5cc3648e5e7b8bf810aa74411035bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/78/d1/5bb826f81d9d490297a348d818ff3ee6dd6f2075b06dde6ea0\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.4.3-py2.py3-none-any.whl size=61374 sha256=9b68de26d815c1e29d0f3bbf3d3cea3780ca48503e906dc50f102eed9eae627c\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/c7/81/a22edb90b0b09a880468b2253bb1df8e9f503337ee15432c64\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.1.3 pycuda-2020.1 pytools-2020.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEFXCm7UvQmc"
      },
      "source": [
        "#3. Desarrollo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVHj_eMNvTKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83123b31-921c-49f5-a41d-df2bb248e0ff"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_elementos =   500000#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from   pycuda.compiler import SourceModule\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) \\\n",
        "              * 1000 + dt.microseconds / 1000.0\n",
        "try:\n",
        "    # CPU: Inicializo el vector resultados con puntajes (de 0 a 9) aleatorios\n",
        "    # con cantidad de elementos ingresada.\n",
        "    vector_resultados_cpu = np.random.randint(0, 10, size = cantidad_elementos)\n",
        "    vector_resultados_cpu = np.array(vector_resultados_cpu, dtype=np.int32)\n",
        "    \n",
        "    # vector_resultados_cpu.astype(np.int32())\n",
        "\n",
        "    # Inicializo en cero el vector frecuencia (puntajes de 0 a 9)\n",
        "    vector_frecuencias_cpu = [0 for i in range(10)]\n",
        "    vector_frecuencias_cpu = np.array(vector_frecuencias_cpu, dtype=np.int32)\n",
        "    # vector_frecuencias_cpu.astype( numpy.int32() )\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"vector respuestas cpu:\")\n",
        "    print(vector_resultados_cpu)\n",
        "    \n",
        "\n",
        "    # CPU - reservo la memoria GPU.\n",
        "    vector_resultados_gpu = cuda.mem_alloc(vector_resultados_cpu.nbytes)\n",
        "    vector_frecuencias_gpu = cuda.mem_alloc(vector_frecuencias_cpu.nbytes)\n",
        "\n",
        "    # GPU - Copio la memoria al GPU.\n",
        "    cuda.memcpy_htod(vector_resultados_gpu, vector_resultados_cpu)\n",
        "    cuda.memcpy_htod(vector_frecuencias_gpu, vector_frecuencias_cpu)\n",
        "\n",
        "    # CPU - Defino la función kernel que ejecutará en GPU.\n",
        "    module = SourceModule(\"\"\"\n",
        "    __global__ void kernel_encuesta(int n, int *frecuencias , int *resultados)\n",
        "    {\n",
        "        int idx = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "\n",
        "        if(idx < n)\n",
        "        {\n",
        "            ++frecuencias[resultados[idx]];        \n",
        "        }\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "    # CPU - Genero la función kernel.\n",
        "    kernel = module.get_function(\"kernel_encuesta\")\n",
        "    \n",
        "    tiempo_gpu = datetime.now()\n",
        "    \n",
        "    dim_hilo = 256\n",
        "    dim_bloque = np.int( (cantidad_elementos + dim_hilo - 1) / dim_hilo )\n",
        "    print( \"Thread x: \", dim_hilo, \", Bloque x:\", dim_bloque )\n",
        "    \n",
        "    # GPU - Ejecuta el kernel.\n",
        "    kernel( np.int32(cantidad_elementos), \\\n",
        "            vector_frecuencias_gpu, \\\n",
        "            vector_resultados_gpu, \\\n",
        "            block=( dim_hilo, 1, 1 ), grid=(dim_bloque, 1,1) )\n",
        "\n",
        "    tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "    # GPU - Copio el resultado desde la memoria GPU.\n",
        "    cuda.memcpy_dtoh( vector_frecuencias_cpu, vector_frecuencias_gpu )\n",
        "\n",
        "    \n",
        "    # CPU - Informo el resultado.\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"vector frecuencia: \")\n",
        "    print(vector_frecuencias_cpu)\n",
        "        \n",
        "    mas_grande = 0\n",
        "    valor_moda = 0\n",
        "\n",
        "    # obtengo la moda del vector_frecuencias_cpu\n",
        "    for rango in range(0, len(vector_frecuencias_cpu)):\n",
        "        if(vector_frecuencias_cpu[rango] > mas_grande):\n",
        "            mas_grande = vector_frecuencias_cpu[rango]\n",
        "            valor_moda = rango\n",
        "    \n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(f\"Para esta ejecución la moda es: {valor_moda}, \")\n",
        "    print(f\"cual ocurrió {mas_grande} veces.\")\n",
        "\n",
        "    tiempo_total = datetime.now() - tiempo_total\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(\"Tiempo Total: \", tiempo_en_ms(tiempo_total),\"[ms]\")\n",
        "    print(\"Tiempo gpu: \", tiempo_en_ms(tiempo_gpu), \"[ms]\" )\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"error: {e}\")\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------\n",
            "vector respuestas cpu:\n",
            "[6 1 7 ... 2 6 9]\n",
            "Thread x:  256 , Bloque x: 1954\n",
            "-------------------------------------------------\n",
            "vector frecuencia: \n",
            "[49 49 49 49 49 49 49 49 43 43]\n",
            "-------------------------------------------------\n",
            "Para esta ejecución la moda es: 0, \n",
            "cual ocurrió 49 veces.\n",
            "-------------------------------------------------\n",
            "Tiempo Total:  15.071 [ms]\n",
            "Tiempo gpu:  0.4 [ms]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sChMbfn8vgG1"
      },
      "source": [
        "#4. Tabla de pasos\n",
        "\n",
        "Paso | Procesador | Funcion | Detalle\n",
        "------------ | ------------ | ------------- | -------------\n",
        "1 | CPU | @param | Lectura del tamaño de vector de Colab.\n",
        "2 | CPU | import | Importa los módulos para funcionar.\n",
        "3 | CPU | datetime.now() | Toma el tiempo actual.\n",
        "4 | CPU | np.random.randint(0, 10, size = cantidad_elementos) | Inicializa el vector _vector_resultados_ con puntajes (de 0 a 9) aleatorios en cada elemento, en una cantidad de elementos ingresada en el paso 1.\n",
        "5 | **GPU** | cuda.mem_alloc()] | Reserva la memoria en GPU.\n",
        "6 | **GPU** | cuda.memcpy_htod() | Copia las memorias desde el CPU al GPU.\n",
        "7 | CPU | SourceModule() | Define el código del kernel.\n",
        "8 | CPU | module.get_function() | Genera la función del kernel GPU\n",
        "9 | CPU | dim_tx/dim_bx | Calcula las dimensiones.\n",
        "10 | **GPU**  | kernel() | Ejecuta el kernel en GPU\n",
        "11 | CPU | cuda.memcpy_dtoh( ) | Copia el resultado desde GPU memoria A a CPU memoria R.\n",
        "12 | CPU | print() | Informo los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX-0yKX0vnTY"
      },
      "source": [
        "#5. Conclusiones\n",
        "\n",
        "* ### 5.1 Breve repaso de los puntos mas relevantes del trabajo.\n",
        "Se definió una función kernel para ser ejecutada en gpu a traves de la clase SourceModule() de cuda[5]. Dentro de la funcion kernel_encuesta() se calcularon las frecuencias de cada votación de una encuesta con puntajes de 0 a 9 representadas por el vector frecuencias. Si bien, el algoritmo no esta funcionando correctamente como se explica en la seccion 5.2 de lecciones aprendidas, se decide dejarlo como esta para evidenciar el error.\n",
        "De todas formas, si observamos los tiempos de ejecución tomados, ya que los hilos se ejecutan por mas que no estan sumarizando correctamente los datos del vector frecuencias, podemos ver que hay una mejora significativa en el procesamiento comparado con la version secuencial que corre en cpu. Podemos ver que la mayor parte del tiempo se consume en el programa en general, mientras que el tiempo de procesamiento del gpu es muy inferior. Con lo cual, de funcionar correctamente, optimizaría su ejecución.\n",
        "\n",
        "* ### 5.2 Explicación sobre las lecciones aprendidas que deja el ejercicio.\n",
        "Como se puede observar, el resultado no es el esperado en el ejercicio. Vemos que el vector de frecuencias empieza a sumar las apariciones de los puntajes, recien cuando se carga una cantidad de elementos para las respuestas por encima de los 40k.\n",
        "Por debajo de esa cantidad, veremos que la mayor frecuencia de cada elemento no supera la cantidad de 1 aparicion y esto no es lo que se ve en el vector de resultados, con lo cual se obtienen datos erroneos.\n",
        "Esto puede deberse, en principio al uso del vector frecuencias. Este se pasa al device (gpu) a traves de la funcion de cuda memcpy_htod(), que genera una copia de la memoria principal a la memoria del dispositivo. En el se realiza un calculo que **no** es independiente del resto[4], dado que al sumar una aparicion, por ejemplo del numero 8 (elemento 8 del vector frecuencias), en varios hilos que estan corriendo en paralelo, solo se sumara una vez, es decir, se incrementa en uno el contador de frecuencias para el numero 8, cuando debería sumar todas las apariciones en cada uno de esos hilos que estan corriendo en paralelo. Sin embargo, al realizar pruebas con cantidades de elemntos superiores, mayores a 50k veremos que si se estan incrementando las frecuencias, en el orden de (cantidad_elementos / 10k), por ejemplo para 500k elementos, las apariciones aleatorias de cada puntaje en el vector de frecuencia ronda los 50. Con esta cantidad de elementos, al definir la cantidad de 256 hilos, los bloques que se necesitaron para resolver fueron de 1954 para llegar a cubrir los 500k. Evidentemente, la cantidad de hilos que acceden concurrentemente al vector frecuencias es de 10k aproximadamente.\n",
        "Este algoritmo no esta funcionando correctamente, pero decidí dejarlo asi para poder evidenciar lo aprendido y, de alguna manera, ver las limitaciones o problemas con los que podemos enfrentarnos al trabajar con este mecanismo.\n",
        "\n",
        "* ### 5.3 Sugerencias para continuar con el ejercicio (funcionalidad o algoritmo).\n",
        "Poder solucionar este problema de concurrencia utilizando eficientemente los hilos. O plantear otra solucion cambiando el algoritmo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNOtiJKMvvxm"
      },
      "source": [
        "#6. Bibliografía\n",
        "\n",
        "* [1] Como Programar en C C++ y Java 4ta Edición Harvey M. Deitel & Paul J. Deitel.\n",
        "* [2] Python Básico - SOA UNLaM: [Python Básico](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb)\n",
        "* [3] Tutorial Point Colab: [Google Colab Tutorial](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/google_colab_tutorial.pdf)\n",
        "* [4] Computacion de alto desempeño en GPU: [pdf](http://so-unlam.com.ar/material-clase/HPC/Computaci%C3%B3n%20de%20alto%20desempe%C3%B1o%20en%20GPU.pdf)\n",
        "* [5] Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "* [6] Repositorio de PyCUDA: [WEB](https://pypi.org/project/pycuda/)"
      ]
    }
  ]
}